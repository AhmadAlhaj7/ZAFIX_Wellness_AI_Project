ğŸ¯ Objective

Develop a frontend interface and reasoning engine for an AI tutor that interacts with learners, analyzes their progress, and provides intelligent feedback.

ğŸ§  Core Logic
Module	Function
lesson_loader.py	Loads educational content (notes, PDFs, slides).
embedding_engine.py	Transforms study material into embeddings for contextual recall.
chat_engine.py	Handles the conversational logic between user and tutor.
ollama_interface.py	Connects to local LLM (e.g., phi3:mini, gemma:2b) for reasoning.
ui/app.py	Streamlit interface for interaction.
âš™ï¸ Workflow
User â†’ Streamlit UI
   â†“
Chat Engine â†’ Interprets query
   â†“
Ollama Interface â†’ LLM reasoning and response generation
   â†“
Output â†’ Tutor feedback / Explanation / Guidance

ğŸ§© Key Features

Real-time chat interface (Streamlit-based).

Local model integration via Ollama for data privacy.

Contextual responses grounded in loaded materials.

ğŸ§  Example Flow

User asks: â€œExplain Newtonâ€™s second law.â€
â†’ System retrieves related content
â†’ AI tutor summarizes and explains with examples.